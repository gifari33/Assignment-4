{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Path input dan output\n",
    "input_path = r'J:\\Drive Saya\\analisa sentimen git\\percobaan 12\\tokens_modified.csv'\n",
    "output_path = r'J:\\Drive Saya\\analisa sentimen git\\percobaan 12\\data_Preprocessing.csv'\n",
    "stopwords_path = r'J:\\Drive Saya\\analisa sentimen git\\percobaan 12\\data stopwords.txt'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghiff\\AppData\\Local\\Temp\\ipykernel_10856\\2128758988.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses selesai! Data dengan kolom tambahan disimpan di J:\\Drive Saya\\analisa sentimen git\\percobaan 12\\data_Preprocessing.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# 1. Menghapus data duplikat\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 2. Load stopwords dari file\n",
    "with open(stopwords_path, 'r') as file:\n",
    "    custom_stopwords = set([line.strip().lower() for line in file])\n",
    "\n",
    "# Fungsi untuk membersihkan tokens\n",
    "def preprocess_tokens(tokens_str):\n",
    "    try:\n",
    "        # Konversi string ke list\n",
    "        tokens = ast.literal_eval(tokens_str)\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Jika tidak bisa dikonversi, kembalikan list kosong\n",
    "        tokens = []\n",
    "    \n",
    "    # Lowercasing dan menghapus stopwords\n",
    "    return [word.lower() for word in tokens if word.lower() not in custom_stopwords]\n",
    "\n",
    "# 3. Terapkan preprocessing pada kolom 'tokens' dan tambahkan kolom baru 'data_Preprocessing'\n",
    "df['data_Preprocessing'] = df['tokens'].apply(preprocess_tokens)\n",
    "\n",
    "# Simpan hasil ke CSV\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Proses selesai! Data dengan kolom tambahan disimpan di {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghiff\\AppData\\Local\\Temp\\ipykernel_10856\\792389999.py:7: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gojek: 32329\n",
      "aplikasi: 21423\n",
      "membantu: 18774\n",
      "driver: 18623\n",
      "bagus: 17584\n",
      "mantap: 15241\n",
      "gopay: 12082\n",
      "good: 10722\n",
      "banget: 9116\n",
      "baik: 7862\n",
      "promo: 7828\n",
      "udah: 7590\n",
      "tolong: 7409\n",
      "gofood: 6307\n",
      "akun: 5304\n",
      "cepat: 5302\n",
      "mahal: 5014\n",
      "susah: 4749\n",
      "masuk: 4745\n",
      "apk: 4663\n",
      "saldo: 4543\n",
      "voucher: 4302\n",
      "update: 4254\n",
      "biaya: 4151\n",
      "mudah: 4070\n",
      "pesan: 4055\n",
      "drivernya: 4001\n",
      "bayar: 3835\n",
      "baru: 3832\n",
      "suka: 3814\n",
      "pelayanan: 3753\n",
      "makanan: 3744\n",
      "order: 3399\n",
      "kecewa: 3368\n",
      "ramah: 3282\n",
      "aplikasinya: 3257\n",
      "pas: 3213\n",
      "udh: 3178\n",
      "bintang: 3173\n",
      "waktu: 3141\n",
      "kali: 3088\n",
      "pesen: 2902\n",
      "jauh: 2841\n",
      "terimakasih: 2792\n",
      "diskon: 2720\n",
      "jelas: 2682\n",
      "ongkir: 2674\n",
      "semoga: 2652\n",
      "harga: 2647\n",
      "nunggu: 2535\n",
      "keren: 2517\n",
      "klo: 2491\n",
      "mohon: 2483\n",
      "transaksi: 2372\n",
      "beli: 2301\n",
      "jam: 2297\n",
      "tepat: 2264\n",
      "puas: 2261\n",
      "buka: 2243\n",
      "gopaylater: 2241\n",
      "pesanan: 2241\n",
      "hp: 2206\n",
      "up: 2193\n",
      "nyaman: 2192\n",
      "layanan: 2190\n",
      "gocar: 2189\n",
      "memuaskan: 2162\n",
      "ribet: 2157\n",
      "gimana: 2139\n",
      "aman: 2105\n",
      "bikin: 2083\n",
      "promonya: 2063\n",
      "parah: 2054\n",
      "masa: 2014\n",
      "uang: 2000\n",
      "orang: 1958\n",
      "sesuai: 1955\n",
      "naik: 1951\n",
      "dah: 1938\n",
      "resto: 1935\n",
      "customer: 1934\n",
      "cancel: 1932\n",
      "minta: 1910\n",
      "memudahkan: 1900\n",
      "gabisa: 1896\n",
      "cs: 1884\n",
      "pembayaran: 1870\n",
      "kurang: 1862\n",
      "perbaiki: 1861\n",
      "upgrade: 1812\n",
      "food: 1776\n",
      "fitur: 1767\n",
      "g: 1748\n",
      "langsung: 1746\n",
      "orderan: 1741\n",
      "sampe: 1739\n",
      "ganti: 1727\n",
      "murah: 1701\n",
      "pihak: 1694\n",
      "masalah: 1680\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "# Load dataset\n",
    "file_path = r'J:\\Drive Saya\\analisa sentimen git\\percobaan 12\\data_Preprocessing.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Parse the 'data_Preprocessing' column\n",
    "df['data_Preprocessing'] = df['data_Preprocessing'].apply(ast.literal_eval)\n",
    "\n",
    "# Flatten all words into a single list\n",
    "all_words = [word for row in df['data_Preprocessing'] for word in row]\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Get 100 most common words\n",
    "most_common_words = word_counts.most_common(100)\n",
    "\n",
    "# Display the results\n",
    "for word, count in most_common_words:\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
